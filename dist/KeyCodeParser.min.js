var e;!function(e){e.Fencing="fencing",e.HeaderPrimaryKey="headerPrimary",e.HeaderSecondaryKey="headerSecondary",e.Highlight="highlight",e.Bold="bold",e.Redact="redact",e.Interrupt="interrupt"}(e||(e={}));const r=Object.fromEntries(new Map([[e.Fencing,{key:"`",repeated:3,rule:e.Fencing}],[e.HeaderPrimaryKey,{key:"\\-",repeated:3,rule:e.HeaderPrimaryKey}],[e.HeaderSecondaryKey,{key:"\\=",repeated:3,rule:e.HeaderSecondaryKey}],[e.Highlight,{key:"\\`",repeated:2,rule:e.Highlight}],[e.Bold,{key:"\\*",repeated:2,rule:e.Bold}],[e.Redact,{key:"\\~",repeated:2,rule:e.Redact}],[e.Interrupt,{key:"\\",repeated:2,rule:e.Interrupt}]]));class t{source;opts;expr;groups;constructor(e,r=""){this.source="string"==typeof e?e:e.source,this.opts=r,this.expr=void 0,this.groups={}}replace(e,r){let t="string"==typeof r?r:r.source;return t=t.replace(n,"$1"),this.source=this.source.replaceAll(e,t),this}createRegex(e={}){return this.expr=new RegExp(this.source,this.opts),this.groups=e,this}get regex(){return this.expr||this.createRegex(),this.expr?this.expr:/()/}}const n=/(^|[^\[])\^/g;var i,a;!function(e){e.TYPE="TYPE",e.RESULT="RESULT"}(i||(i={})),function(e){e.AllowableSpace="AllowableSpace",e.Fencing="Fencing",e.HeadingSect="HeadingSect",e.TextBlock="TextBlock",e.Paragraph="Paragraph",e.Highlight="Highlight",e.Span="Span"}(a||(a={}));class s{blockRules;inlineRules;constructor(n=r){this.blockRules=function(r){const n=`${r[e.Fencing].key}{${r[e.Fencing].repeated}}`,s=`${r[e.HeaderPrimaryKey].key}{${r[e.HeaderPrimaryKey].repeated}}`,l=`${r[e.HeaderSecondaryKey].key}{${r[e.HeaderPrimaryKey].repeated}}`,o=/\n|$/,c=new t(/ *?(EndOfLine%)/).replace("EndOfLine%",o).createRegex(),h=new t(/HeaderPrimaryKey%|HeaderSecondaryKey%/).replace("HeaderPrimaryKey%",s).replace("HeaderSecondaryKey%",l).createRegex();return Object.fromEntries(new Map([[a.AllowableSpace,{patterns:new t(/^(?<RESULT>AllowableSpace%)/).replace("AllowableSpace%",c.regex).createRegex({[i.RESULT]:1}),hasTokens:!1}],[a.Fencing,{patterns:new t(/^(?<TYPE>FencingKey%)(?<RESULT>AllContainedChar%|$)(?:FencingKey%)/).replace("FencingKey%",n).replace("AllContainedChar%",/[\s\S]*?/).createRegex({[i.TYPE]:1,[i.RESULT]:2}),hasTokens:!0}],[a.HeadingSect,{patterns:new t(/^(?<RESULT>EmptySurronding%|.+\n)(?<TYPE>SectionHeader%)(?:EndOfLine%)/).replace("SectionHeader%",h.regex).replace("EmptySurronding%",/\n(?!\s*?\n)/).replace("EndOfLine%",o).createRegex({[i.RESULT]:1,[i.TYPE]:2}),hasTokens:!1}],[a.TextBlock,{patterns:new t(/^(?<RESULT>AllCharInLine%AllowableSpace%)/).replace("AllowableSpace%",c.regex).replace("AllCharInLine%",/[^\n]+/).createRegex({[i.RESULT]:1}),hasTokens:!0}]]))}(n),this.inlineRules=function(r){const n=`${r[e.Bold].key}{${r[e.Bold].repeated}}`,s=`${r[e.Redact].key}{${r[e.Redact].repeated}}`,l=(r[e.Interrupt].key,r[e.Interrupt].repeated,`${r[e.Highlight].key}{${r[e.Highlight].repeated}}`),o=new t(/Bold%|Redact%/).replace("Bold%",n).replace("Redact%",s).createRegex();return Object.fromEntries(new Map([[a.Paragraph,{patterns:new t(/^(?!HighlightKey%|Spanable%)(?<RESULT>[\s\S]*?)(?=HighlightKey%|Spanable%|$)/).replace("Spanable%",o.regex).replace("HighlightKey%",l).createRegex({[i.RESULT]:1}),hasTokens:!1}],[a.Highlight,{patterns:new t(/(HighlightKey%)(?:\~(?<TYPE>\S*) ?|)(?<RESULT>[\s\S]*?)(\1)/).replace("HighlightKey%",l).createRegex({[i.TYPE]:2,[i.RESULT]:3}),hasTokens:!0}],[a.Span,{patterns:new t(/(?<TYPE>Spanable%)(?<RESULT>[\s\S]*?)\1/).replace("Spanable%",o.regex).createRegex({[i.TYPE]:1,[i.RESULT]:2}),hasTokens:!1}]]))}(n)}tokenize(e,r,t,n,i){const a=e?.groups?e.groups?.RESULT||e[t.RESULT]||"null":e[t.RESULT]||e[1],s=e?.groups?e.groups?.TYPE||e[t.TYPE]||"null":e[t.TYPE]||"";return{keyName:r,raw:i?(i?.raw||"")+e[0]:e[0],text:i?(i?.text||"")+(a||""):a||"",depth:n,type:s}}}class l{Tokenizer;tokens;inlineQueue;constructor(e=r,t){Array.isArray(e)&&(e=function(...e){const r=new Map;for(let t=0;t<e.length;t++)r.set(e[t].rule,e[t]);return Object.fromEntries(r)}(...e));const n=Object.assign(Object.assign({},r),e);this.Tokenizer=new s(n),this.tokens=t,this.inlineQueue=[]}lexalizeFrom(e,r=this.Tokenizer.blockRules,t,n,i){const s=Object.keys(r),l=s.length;let o,c=i||0;for(let i=n||0;i<l;i++){const n=s[i],l=r[n];if((o=l.patterns.regex.exec(e))&&o[0].length>0){let s,h;t?(t?.children||(t.children=new Array),h=t.children):h=this.tokens;const p=h?.length-1||0,g=h[p>=0?p:0];g&&g.keyName==n?(s=this.Tokenizer.tokenize(o,n,l.patterns.groups,c,g),h.pop(),l?.hasTokens&&this.inlineQueue.pop()):s=this.Tokenizer.tokenize(o,n,l.patterns.groups,c),l?.hasTokens&&(a.Paragraph in r?this.lexalizeFrom(s.text,r,s,0,c+1):this.inlineQueue.push(s)),h.push(s),e=e.substring(o[0].length),i=-1}}if(a.TextBlock in r)for(let e=0;e<this.inlineQueue.length;e++)this.lexalizeFrom(this.inlineQueue[e].text,this.Tokenizer.inlineRules,this.inlineQueue[e],0,1)}}class o{tokens;interpretter;constructor(e){this.tokens=[],this.interpretter=new l(e,this.tokens)}parse(e,r){return this.tokens.length>0&&(this.tokens=[]),e=e.trim(),this.interpretter.lexalizeFrom(e),this.tokens}*getOrderedChildren(){for(const e of this.tokens)if(e?.children)for(const r of e.children)yield r}getStringArray(){const e=new Array;return this.iterateTokens((r=>{if(r?.children){const t=r.children.length;for(let n=0;n<t;n++)e.push(r.children[n].text)}else e.push(r.text)})),e}iterateTokens(e,r){r||(r=this.tokens);for(let t=0;t<r.length;t++)r[t]?.children?this.iterateTokens(e,r[t].children):e(r[t])}}export{o as KeyCodeParser};